{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "464abe38",
   "metadata": {},
   "source": [
    "# Calculate Cross Proxy Perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce73e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "load_dotenv()\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "base_dir = os.getenv('BASEDIR')\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# from lightgbm import LGBMClassifier\n",
    "from flaml.default import LGBMClassifier\n",
    "from itertools import chain, combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e77680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac797c5-826c-4d10-b413-a24189b39fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='qanda'\n",
    "datasets = [dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c15c14-5299-40c5-8a4e-1698827ad1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_groundtruths =['URLa_FR', 'URLb_FR']\n",
    "lr_groundtruths =['HASHTAG','URL_LR','POLITICIAN_1H_LR', 'PARTY_FOLLOWER_LR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf46d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = {dataset : defaultdict(dict) for dataset in datasets}\n",
    "gt_f1 = {dataset : defaultdict(dict) for dataset in datasets}\n",
    "overlap_f1 = {dataset : defaultdict(dict) for dataset in datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6797fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def all_combinations(l):\n",
    "    return(itertools.product(l, repeat=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa5584d-3c20-4798-aa1b-f05f6f6f900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vector(fp):\n",
    "    with open(fp, 'rb') as rf:\n",
    "        vec = pk.load(rf)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508d69c7-3139-4981-a3cd-de6abee8041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "granularity = '_per_user'\n",
    "feature = 'use'\n",
    "\n",
    "for dataset in datasets:\n",
    "    for train, test in itertools.chain(all_combinations(lr_groundtruths),all_combinations(fr_groundtruths)):\n",
    "        train_path = os.path.join(base_dir,'data','03_processed',dataset,'ground_truth', dataset+'_'+train+'_'+granularity+'.pk')\n",
    "        if not os.path.exists(train_path):\n",
    "            continue\n",
    "        test_path = os.path.join(base_dir,'data','03_processed',dataset,'ground_truth', dataset+'_'+test+'_'+granularity+'.pk')\n",
    "        if not os.path.exists(test_path):\n",
    "            continue\n",
    "\n",
    "        y_train = load_vector(train_path).values\n",
    "        mask_train = y_train >= 0\n",
    "\n",
    "        y_test = load_vector(test_path).values\n",
    "        mask_test = y_test >= 0\n",
    "        mask = mask_train | mask_test\n",
    "        \n",
    "        if any(mask):\n",
    "            # gt_f1[dataset][train][test] = f1_score(y_train[mask], y_test[mask],average='macro')\n",
    "\n",
    "            # y = y_train[mask]\n",
    "            y = y_train[mask_train]\n",
    "            \n",
    "            feature_path = os.path.join(base_dir,'data','03_processed',dataset,'features', dataset+'_'+feature+'_'+granularity+'.pk')\n",
    "            X_orig = load_vector(feature_path)\n",
    "            \n",
    "            # X = X_orig[mask]\n",
    "            X = X_orig[mask_train]\n",
    "            et = LGBMClassifier(is_unbalance=True,n_estimators=200, n_jobs=-1, verbose=-1, seed=123)\n",
    "            if train == test:\n",
    "                # et = LGBMClassifier(colsample_bytree=0.8, class_weight='balanced', n_jobs=-1)\n",
    "                # validation instance\n",
    "                skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "                # getting the model validation predictions\n",
    "                preds = cross_val_predict(et, X, y, cv=skf, method='predict_proba')\n",
    "            else:\n",
    "                # et = LGBMClassifier(colsample_bytree=0.8, class_weight='balanced', n_jobs=-1)\n",
    "                et.fit(X,y)\n",
    "                X_text = X = X_orig[mask_test]\n",
    "                preds = et.predict_proba(X_text)\n",
    "            if train in fr_groundtruths:\n",
    "                preds = preds[:,1]\n",
    "            # evaluating the model\n",
    "            try:\n",
    "                if test == 'POLITICIAN_LR' and train == 'POLITICIAN_1H_LR':\n",
    "                    N = preds.shape[0]\n",
    "                    preds = np.c_[np.zeros(N),preds]\n",
    "                print('Area under the ROC Curve:', roc_auc_score(y_test[mask_test], preds, multi_class='ovo'))\n",
    "                performance[dataset][train][test] = roc_auc_score(y_test[mask_test], preds, multi_class='ovo')\n",
    "            except Exception as e:\n",
    "                print('Failed for:', train, test)\n",
    "                raise(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3830e6d8-9dd4-4747-8841-9d7c585e7220",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = ['HASHTAG','URL_LR','POLITICIAN_1H_LR','PARTY_FOLLOWER_LR','USER_FR','URLa_FR','URLb_FR']\n",
    "pd.DataFrame(dict(performance[dataset])).reindex(index=col_order, columns=col_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74467da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = ['HASHTAG','URL_LR','POLITICIAN_1H_LR','PARTY_FOLLOWER_LR','URLa_FR','URLb_FR']\n",
    "performance_dfs = {dataset: pd.DataFrame(dict(performance[dataset])).reindex(index=col_order, columns=col_order) for dataset in datasets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aeae1c1-ea7c-4183-bc74-0ab24708683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_dfs['qanda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e31ca1-85d8-49f7-b103-f7fbee72c015",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_dfs['qanda'].to_csv(os.path.join(base_dir, 'data', '04_results', 'qanda_cross_gt_auc.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rr",
   "language": "python",
   "name": "rr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
