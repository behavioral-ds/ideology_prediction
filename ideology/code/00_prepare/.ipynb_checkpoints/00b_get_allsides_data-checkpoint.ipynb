{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621a20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from communityfeedback import *\n",
    "from time import sleep\n",
    "from rich.progress import track\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome('/home/rohit/chromedriver',chrome_options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e13578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_bias_url = 'https://www.allsides.com/media-bias/ratings?field_featured_bias_rating_value=All&field_news_source_type_tid%5B%5D=2&field_news_source_type_tid%5B%5D=3&field_news_bias_nid_1%5B1%5D=1&field_news_bias_nid_1%5B2%5D=2&field_news_bias_nid_1%5B3%5D=3&title='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832420e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_page_source(url):\n",
    "    driver.get(url)\n",
    "    for i in range(30):\n",
    "        sleep(3)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "    return(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97972e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table(full_table):\n",
    "    print('Web scraper is parsing the table!')\n",
    "    # only collects data from the first table that shows not the ones that load after the infinite scroll.\n",
    "    for url in [media_bias_url]:\n",
    "        source = get_full_page_source(url) #requests.get(url)\n",
    "        soup = BeautifulSoup(source, 'lxml')\n",
    "        main_table = soup.select('tbody tr')\n",
    "\n",
    "        for row in main_table:\n",
    "            f = dict()\n",
    "            f['News Source'] = row.select_one('.source-title').text.strip()\n",
    "            f['AllSides Bias Rating'] = row.select_one('.views-field-field-bias-image a')['href'].split('/')[-1].replace(\"-\",\" \")\n",
    "            f['News Media Info'] = 'https://www.allsides.com' + row.select_one('.source-title a')['href']\n",
    "            f['Agree'] = int(row.select_one('.agree').text)\n",
    "            f['Disagree'] = int(row.select_one('.disagree').text)\n",
    "#             f['Ratio'] = (f['Agree'] / f['Disagree'])\n",
    "#             f['Community Feedback'] = community_vote(f['Ratio'])\n",
    "#             f['Ratio'] = '{:.3f}'.format(f['Ratio'])\n",
    "\n",
    "            full_table.append(f)  # adds it to the empty list\n",
    "\n",
    "        sleep(10)  # this is due to the ten seconds before request in robots.txt\n",
    "    return full_table\n",
    "\n",
    "def website(full_table):\n",
    "    # enters into the info page and parses out the info\n",
    "    for f in tqdm(full_table):\n",
    "        source = requests.get(f['News Media Info'])\n",
    "        soup = BeautifulSoup(source.content, 'lxml')\n",
    "        try:\n",
    "            # getting the website link to news source\n",
    "            locate_html_class = soup.find('div', {'class': 'dynamic-grid'})\n",
    "            locate_link = locate_html_class.find('a')['href']\n",
    "            f['News Source Site'] = locate_link\n",
    "        except:\n",
    "            f['News Source Site'] = 'N/A'\n",
    "        try:\n",
    "            # getting the creation date of the news source\n",
    "            locate_html_class = soup.find('div', {'class': 'dynamic-grid'})\n",
    "            locate_creation_date = locate_html_class.find_all('p')[1].text.split('.')[-1].strip()\n",
    "            f['Established'] = locate_creation_date\n",
    "        except:\n",
    "            f['Established'] = 'N/A'\n",
    "        try:\n",
    "            # who the news source owned by\n",
    "            locate_html_class = soup.find('div', {'class': 'dynamic-grid'})\n",
    "            locate_owned_by = locate_html_class.find_all('p')[2].text.split(':')[-1].strip()\n",
    "            f['Owned by'] = locate_owned_by\n",
    "        except:\n",
    "            f['Owned by'] = 'N/A'\n",
    "        try:\n",
    "            # What the site covers / about\n",
    "            locate_html_class = soup.find('p', {'class': 'more'})\n",
    "            locate_about_paragraph = locate_html_class.get_text().strip()\n",
    "            f['Info Paragraph'] = locate_about_paragraph\n",
    "        except:\n",
    "            f['Info Paragraph'] = 'N/A'\n",
    "        sleep(10)\n",
    "        try:\n",
    "            locate_html_class = soup.find('div', {'class': 'dynamic-grid'})\n",
    "            locate_link = locate_html_class.find('a')['href']\n",
    "        except:\n",
    "            f['Wikipedia Page'] = 'N/A'\n",
    "        # Sleep 10 seconds to follow robots.txt rules https://www.allsides.com/robots.txt\n",
    "        sleep(1)\n",
    "    print('Parsing has finished')  \n",
    "    return full_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9695c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_table = [] \n",
    "full_table = table(full_table)\n",
    "full_table_w_websites = website(full_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c3995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(full_table_w_websites).to_csv(f'{base_dir}/data/02_ground_truth_data/all_allsides_media_bias.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaEnv",
   "language": "python",
   "name": "condaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
