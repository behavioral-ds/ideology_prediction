{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbd73b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "load_dotenv()\n",
    "from gdtm.helpers.common import load_flat_dataset\n",
    "base_dir = os.getenv('BASEDIR')\n",
    "import re\n",
    "import pickle as pk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ed0601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f995e90",
   "metadata": {},
   "source": [
    "### Qanda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2739fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(base_dir,'data','01_raw_data','qanda','qanda_episodes.csv'), dtype=str)\n",
    "\n",
    "data['hashtags'] = data['hashtags'].fillna('').apply(lambda s: s.split(';;;'))\n",
    "\n",
    "data['mentions'] = data['mentions'].fillna('').apply(lambda s: s.split(';;;'))\n",
    "\n",
    "data['urls'] = data['urls'].fillna('').apply(lambda s: s.split(';;;'))\n",
    "\n",
    "data['text_ht_censored'] = data['text'].apply(lambda t: re.sub(r'http\\S+', '<URL>', t)).apply(lambda t: re.sub(\"#[A-Za-z0-9_]+\",\"<HASHTAG>\", t)) \n",
    "data['text'] = data['text'].apply(lambda t: re.sub(r'http\\S+', '', t)).apply(lambda t: re.sub(\"#[A-Za-z0-9_]+\",\"\", t)).apply(lambda t: re.sub(r'@\\S+', '', t))\n",
    "\n",
    "data['rid'] = data['rid'].combine_first(data['tid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "444071d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(base_dir,'data','01_raw_data','qanda','qanda_per_post.pk'), 'wb') as wf:\n",
    "    pk.dump(data, wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71dd3d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 275032/275032 [02:25<00:00, 1887.18it/s]\n"
     ]
    }
   ],
   "source": [
    "data_per_episode = data.groupby(['uid','episode']).progress_apply(lambda d: pd.DataFrame({'text' : ' '.join(d['text']),'hashtags': [[e for u in d['hashtags'] for e in u if e != '']],'rid':[list(d['rid'])], 'urls' : [[e for u in d['urls'] for e in u if e != '']] }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f091d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(base_dir,'data','01_raw_data','qanda','qanda_per_episode.pk'), 'wb') as wf:\n",
    "    pk.dump(data_per_episode, wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47bd0930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100114/100114 [00:53<00:00, 1883.24it/s]\n"
     ]
    }
   ],
   "source": [
    "data_per_user = data.groupby('uid').progress_apply(lambda d: pd.DataFrame({'text' : ' '.join(d['text']),'hashtags': [[e for u in d['hashtags'] for e in u if e != '']],'rid':[list(d['rid'])], 'urls' : [[e for u in d['urls'] for e in u if e != '']] }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c373d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(base_dir,'data','01_raw_data','qanda','qanda_per_user.pk'), 'wb') as wf:\n",
    "    pk.dump(data_per_user ,wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2d3a5e",
   "metadata": {},
   "source": [
    "### Ausvotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e39fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(base_dir,'data','01_raw_data','ausvotes','ausvotes.csv'), dtype=str, header=None, names=['tid','cid','uid','created_at','text','urls', 'urls2'])\n",
    "\n",
    "data['urls'] = data['urls'].fillna('').apply(lambda s: s.split(';;;')) + data['urls2'].fillna('').apply(lambda s: s.split(';;;'))\n",
    "data = data[~data.text.isna()]\n",
    "data['text'] = data['text'].apply(lambda t: re.sub(r'http\\S+', '', t)).apply(lambda t: re.sub(\"#[A-Za-z0-9_]+\",\"\", t)).apply(lambda t: re.sub(r'@\\S+', '', t))\n",
    "data['cid'] = data['cid'].combine_first(data['tid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7559dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(base_dir,'data','01_raw_data','ausvotes','ausvotes_per_post.pk'), 'wb') as wf:\n",
    "    pk.dump(data, wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6a1f5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265350/265350 [02:16<00:00, 1943.76it/s]\n"
     ]
    }
   ],
   "source": [
    "data_per_user = data.groupby('uid').progress_apply(lambda d: pd.DataFrame({'text' : ' '.join(d['text']), 'rid':[list(d['cid'])], 'urls' : [[e for u in d['urls'] for e in u if e != '']] }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a0b6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(base_dir,'data','01_raw_data','ausvotes','ausvotes_per_user.pk'), 'wb') as wf:\n",
    "    pk.dump(data_per_user, wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585705a6",
   "metadata": {},
   "source": [
    "### Social Sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e32b345",
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_data = pd.read_csv(os.path.join(base_dir,'data','01_raw_data','socialsense','fb_for_stance.csv'), dtype=str)[['index','text','text_urls', 'timestamp', 'user']]\n",
    "fb_data['urls'] = fb_data['text_urls'].fillna('').apply(lambda s: s.strip().split(','))\n",
    "fb_data['text'] = fb_data['text'].apply(lambda t: re.sub(r'http\\S+', '', t)).apply(lambda t: re.sub(\"#[A-Za-z0-9_]+\",\"\", t)).apply(lambda t: re.sub(r'@\\S+', '', t))\n",
    "fb_data['id'] = fb_data['index']\n",
    "\n",
    "fb_data['uid'] = fb_data['user']\n",
    "fb_data['created_at'] = fb_data['timestamp']\n",
    "fb_data['is_twitter'] = False\n",
    "\n",
    "fb_data = fb_data[['id', 'text','urls', 'uid', 'created_at', 'is_twitter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0f56ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_uid_index = pd.read_csv(os.path.join(base_dir,'data','01_raw_data','socialsense','socialsense_id_uid_index.csv'), dtype=str, header=None, names=['id', 'cid','uid'])[['id','uid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb8280e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_data = pd.read_csv(os.path.join(base_dir,'data','01_raw_data','socialsense','tw_for_stance_unrolled.csv'), dtype=str)[['id', 'text','text_urls_unrolled', 'date']]\n",
    "tw_data = pd.merge(tw_data,id_uid_index, how='left', on='id')\n",
    "tw_data['urls'] = tw_data['text_urls_unrolled'].fillna('').apply(lambda s: s.strip().split(','))\n",
    "tw_data['text'] = tw_data['text'].apply(lambda t: re.sub(r'http\\S+', '', t)).apply(lambda t: re.sub(\"#[A-Za-z0-9_]+\",\"\", t)).apply(lambda t: re.sub(r'@\\S+', '', t))\n",
    "\n",
    "tw_data['created_at'] = tw_data['date']\n",
    "tw_data['is_twitter'] = True\n",
    "\n",
    "tw_data = tw_data[['id', 'text','urls', 'uid', 'created_at', 'is_twitter']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5ea4cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([tw_data, fb_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d8641618",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(base_dir,'data','01_raw_data','socialsense','socialsense_per_post.pk'), 'wb') as wf:\n",
    "    pk.dump(data, wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01a83002",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtered = data[~data['uid'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ebbacaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49442/49442 [00:19<00:00, 2486.97it/s]\n"
     ]
    }
   ],
   "source": [
    "data_per_user = data_filtered.groupby('uid').progress_apply(lambda d: pd.DataFrame({'text' : ' '.join(d['text']), 'urls' : [[e for u in d['urls'] for e in u if e != '']] }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cd8968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(base_dir,'data','01_raw_data','socialsense','socialsense_per_user.pk'), 'wb') as wf:\n",
    "    pk.dump(data_per_user, wf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaEnv",
   "language": "python",
   "name": "condaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
