{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61444b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "load_dotenv()\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "base_dir = os.getenv('BASEDIR')\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6807711a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prep Hashtag Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b047808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_labels = pd.read_csv(os.path.join(base_dir,'data','02_ground_truth_data','qanda_labelled_hashtags.csv'))\n",
    "def assign_polarity(e):\n",
    "    if(e in {'left', 'more left', 'left?', 'left_'}):\n",
    "        return -1\n",
    "    elif(e in ['right', 'more right', 'right?']):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "hashtag_labels['polarity'] = hashtag_labels['label'].apply(assign_polarity)\n",
    "hashtag_labels = hashtag_labels[~hashtag_labels['polarity'].isna()]\n",
    "\n",
    "left_hashtags = hashtag_labels[hashtag_labels['polarity'] == -1]['hashtags']\n",
    "right_hashtags = hashtag_labels[hashtag_labels['polarity'] == 1]['hashtags']\n",
    "\n",
    "def ground_truth_hashtag(ht):\n",
    "    if ht in left_hashtags.values:\n",
    "        return -1\n",
    "    elif ht in right_hashtags.values:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def handle_labels(s):\n",
    "    if np.isnan(s):\n",
    "        return -1\n",
    "    elif s > 0:\n",
    "        return 2\n",
    "    elif s == 0:\n",
    "        return 0\n",
    "    elif s < 0:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be870769",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['qanda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0b702eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37740/1614358857.py:5: RuntimeWarning: Mean of empty slice\n",
      "  ht_gt = data_hashtags.apply(lambda l: np.nanmean(list(map(ground_truth_hashtag, l)))).apply(handle_labels)\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    with open(os.path.join(base_dir,'data','01_raw_data',dataset, dataset+'_per_user'+'.pk'), 'rb') as rf:\n",
    "        data = pk.load(rf)\n",
    "        data_hashtags = data['hashtags']\n",
    "        ht_gt = data_hashtags.apply(lambda l: np.nanmean(list(map(ground_truth_hashtag, l)))).apply(handle_labels)\n",
    "        Path( os.path.join(base_dir,'data','03_processed',dataset,'ground_truth') ).mkdir( parents=True, exist_ok=True )\n",
    "    with open(os.path.join(base_dir,'data','03_processed',dataset,'ground_truth', dataset+'_HASHTAG__per_user.pk'), 'wb') as wf:\n",
    "        pk.dump(ht_gt, wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07da886b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prep URL Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eb9469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_lr = pd.read_csv(os.path.join(base_dir,'data','02_ground_truth_data','url_data','domain_allsides_reuters_lr.csv')).set_index('domain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfd8c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tldextract\n",
    "def extract_domain(url):\n",
    "    ext = tldextract.extract(url)\n",
    "    return('.'.join([ext.domain, ext.suffix]))\n",
    "\n",
    "def handle_labels(s):\n",
    "    if np.isnan(s):\n",
    "        return -1\n",
    "    elif s > 0:\n",
    "        return 2\n",
    "    elif s == 0:\n",
    "        return 0\n",
    "    elif s < -1*0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def get_url_ideology(full_url):\n",
    "    domain = extract_domain(full_url)\n",
    "    try:\n",
    "        return(domain_lr.loc[domain].stance)\n",
    "    except Exception as e:\n",
    "        return(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bd9e832-738c-4c49-ada2-4ecbaed641c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=['qanda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cae8a6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = ['qanda', 'ausvotes', 'riot', 'parler', 'socialsense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eccefca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                       | 0/103074 [00:00<?, ?it/s]/tmp/ipykernel_205527/4107140752.py:6: RuntimeWarning: Mean of empty slice\n",
      "  url_ideology = data['urls'].progress_apply(lambda l: np.nanmean([get_url_ideology(e) for e in l])).apply(handle_labels)\n",
      "100%|███████████████████████████████████████████████████████| 103074/103074 [00:07<00:00, 13693.08it/s]\n"
     ]
    }
   ],
   "source": [
    "granularity = '_per_user'\n",
    "for dataset in datasets:\n",
    "    data_path = os.path.join(base_dir,'data','01_raw_data',dataset, dataset+granularity+'.pk')\n",
    "    with open(data_path, 'rb') as rf:\n",
    "        data = pk.load(rf)\n",
    "        url_ideology = data['urls'].progress_apply(lambda l: np.nanmean([get_url_ideology(e) for e in l])).apply(handle_labels)\n",
    "    Path( os.path.join(base_dir,'data','03_processed',dataset,'ground_truth') ).mkdir( parents=True, exist_ok=True )\n",
    "    with open(os.path.join(base_dir,'data','03_processed',dataset,'ground_truth', dataset+'_URL_LR_'+granularity+'.pk'), 'wb') as wf:\n",
    "        pk.dump(url_ideology, wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a737d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prep FR URL Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f66d555e",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_lr = pd.read_csv(os.path.join(base_dir,'data','02_ground_truth_data','url_data','domain_allsides_reuters_lr.csv')).set_index('domain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1571bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tldextract\n",
    "def extract_domain(url):\n",
    "    ext = tldextract.extract(url)\n",
    "    return('.'.join([ext.domain, ext.suffix]))\n",
    "\n",
    "def handle_labels(s):\n",
    "    return s > 0.5\n",
    "    \n",
    "def get_url_ideology(full_url):\n",
    "    domain = extract_domain(full_url)\n",
    "    try:\n",
    "        return(domain_lr.loc[domain].stance)\n",
    "    except Exception as e:\n",
    "        return(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36ffe409",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['qanda', 'ausvotes', 'riot', 'parler', 'socialsense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16c4dc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                       | 0/103074 [00:00<?, ?it/s]/tmp/ipykernel_37740/2878698012.py:6: RuntimeWarning: Mean of empty slice\n",
      "  url_ideology = data['urls'].progress_apply(lambda l: np.nanmean([get_url_ideology(e) for e in l])).apply(handle_labels)\n",
      "100%|███████████████████████████████████████████████████████| 103074/103074 [00:07<00:00, 13949.00it/s]\n",
      "100%|████████████████████████████████████████████████████████| 273874/273874 [01:48<00:00, 2534.07it/s]\n",
      "100%|███████████████████████████████████████████████████████| 574281/574281 [00:43<00:00, 13305.19it/s]\n",
      "100%|███████████████████████████████████████████████████████| 120048/120048 [00:04<00:00, 26270.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 49442/49442 [00:03<00:00, 12805.89it/s]\n"
     ]
    }
   ],
   "source": [
    "granularity = '_per_user'\n",
    "for dataset in datasets:\n",
    "    data_path = os.path.join(base_dir,'data','01_raw_data',dataset, dataset+granularity+'.pk')\n",
    "    with open(data_path, 'rb') as rf:\n",
    "        data = pk.load(rf)\n",
    "        url_ideology = data['urls'].progress_apply(lambda l: np.nanmean([get_url_ideology(e) for e in l])).apply(handle_labels)\n",
    "    Path( os.path.join(base_dir,'data','03_processed',dataset,'ground_truth') ).mkdir( parents=True, exist_ok=True )\n",
    "    with open(os.path.join(base_dir,'data','03_processed',dataset,'ground_truth', dataset+'_URLa_FR_'+granularity+'.pk'), 'wb') as wf:\n",
    "        pk.dump(url_ideology, wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50959de",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prep FR URL MBFC Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c55da920-7977-4725-944e-84f7cd2347d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfc = pd.read_csv(os.path.join(base_dir,'data','02_ground_truth_data','url_data','mbfc','mbfc_poltical.tsv'), delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "246c85a8-9285-491a-a5c0-3538e6796074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_url</th>\n",
       "      <th>source_url_normalized</th>\n",
       "      <th>ref</th>\n",
       "      <th>fact</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://crooked.com</td>\n",
       "      <td>crooked.com</td>\n",
       "      <td>https://mediabiasfactcheck.com/crooked-media/</td>\n",
       "      <td>high</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://deepleftfield.info</td>\n",
       "      <td>deepleftfield.info</td>\n",
       "      <td>https://mediabiasfactcheck.com/deep-left-field/</td>\n",
       "      <td>mixed</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://antifascistnews.net</td>\n",
       "      <td>antifascistnews.net</td>\n",
       "      <td>https://mediabiasfactcheck.com/anti-fascist-news/</td>\n",
       "      <td>high</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.cnn.com</td>\n",
       "      <td>cnn.com</td>\n",
       "      <td>http://mediabiasfactcheck.com/cnn/</td>\n",
       "      <td>mixed</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.allthatsfab.com</td>\n",
       "      <td>allthatsfab.com</td>\n",
       "      <td>http://mediabiasfactcheck.com/all-thats-fab/</td>\n",
       "      <td>mixed</td>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>http://www.unz.com</td>\n",
       "      <td>unz.com</td>\n",
       "      <td>https://mediabiasfactcheck.com/the-unz-report/</td>\n",
       "      <td>low</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>http://www.westernsentinel.com</td>\n",
       "      <td>westernsentinel.com</td>\n",
       "      <td>https://mediabiasfactcheck.com/western-sentinel/</td>\n",
       "      <td>low</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>http://www.uschronicle.com</td>\n",
       "      <td>uschronicle.com</td>\n",
       "      <td>http://mediabiasfactcheck.com/us-chronicle/</td>\n",
       "      <td>low</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>https://www.thepublicdiscourse.com</td>\n",
       "      <td>thepublicdiscourse.com</td>\n",
       "      <td>https://mediabiasfactcheck.com/witherspoon-ins...</td>\n",
       "      <td>low</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>http://www.vdare.com</td>\n",
       "      <td>vdare.com</td>\n",
       "      <td>http://mediabiasfactcheck.com/vdare/</td>\n",
       "      <td>low</td>\n",
       "      <td>right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>859 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             source_url   source_url_normalized  \\\n",
       "0                   https://crooked.com             crooked.com   \n",
       "1             http://deepleftfield.info      deepleftfield.info   \n",
       "2           https://antifascistnews.net     antifascistnews.net   \n",
       "3                    http://www.cnn.com                 cnn.com   \n",
       "4            http://www.allthatsfab.com         allthatsfab.com   \n",
       "..                                  ...                     ...   \n",
       "854                  http://www.unz.com                 unz.com   \n",
       "855      http://www.westernsentinel.com     westernsentinel.com   \n",
       "856          http://www.uschronicle.com         uschronicle.com   \n",
       "857  https://www.thepublicdiscourse.com  thepublicdiscourse.com   \n",
       "858                http://www.vdare.com               vdare.com   \n",
       "\n",
       "                                                   ref   fact   bias  \n",
       "0        https://mediabiasfactcheck.com/crooked-media/   high   left  \n",
       "1      https://mediabiasfactcheck.com/deep-left-field/  mixed   left  \n",
       "2    https://mediabiasfactcheck.com/anti-fascist-news/   high   left  \n",
       "3                   http://mediabiasfactcheck.com/cnn/  mixed   left  \n",
       "4         http://mediabiasfactcheck.com/all-thats-fab/  mixed   left  \n",
       "..                                                 ...    ...    ...  \n",
       "854     https://mediabiasfactcheck.com/the-unz-report/    low  right  \n",
       "855   https://mediabiasfactcheck.com/western-sentinel/    low  right  \n",
       "856        http://mediabiasfactcheck.com/us-chronicle/    low  right  \n",
       "857  https://mediabiasfactcheck.com/witherspoon-ins...    low  right  \n",
       "858               http://mediabiasfactcheck.com/vdare/    low  right  \n",
       "\n",
       "[859 rows x 5 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3552b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfc = pd.read_csv(os.path.join(base_dir,'data','02_ground_truth_data','url_data','mbfc','mbfc_poltical.tsv'), delimiter='\\t')\n",
    "mbfc = mbfc[mbfc['bias'] == 'right']\n",
    "mbfc['domain'] = mbfc['source_url_normalized']\n",
    "mbfc['stance'] = 1.0\n",
    "mbfc = mbfc.set_index('domain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eebec572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tldextract\n",
    "def extract_domain(url):\n",
    "    ext = tldextract.extract(url)\n",
    "    return('.'.join([ext.domain, ext.suffix]))\n",
    "\n",
    "def handle_labels(s):\n",
    "    return s > 0.5\n",
    "    \n",
    "def get_url_ideology(full_url):\n",
    "    domain = extract_domain(full_url)\n",
    "    try:\n",
    "        return(mbfc.loc[domain].stance)\n",
    "    except Exception as e:\n",
    "        return(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6df53400",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['qanda', 'ausvotes', 'riot', 'parler', 'socialsense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ab52d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                       | 0/103074 [00:00<?, ?it/s]/tmp/ipykernel_37740/3766268766.py:6: RuntimeWarning: Mean of empty slice\n",
      "  url_ideology = data['urls'].progress_apply(lambda l: np.nanmean([get_url_ideology(e) for e in l])).apply(handle_labels)\n",
      "100%|███████████████████████████████████████████████████████| 103074/103074 [00:05<00:00, 17251.44it/s]\n",
      "100%|████████████████████████████████████████████████████████| 273874/273874 [01:14<00:00, 3689.48it/s]\n",
      "100%|███████████████████████████████████████████████████████| 574281/574281 [00:39<00:00, 14624.19it/s]\n",
      "100%|███████████████████████████████████████████████████████| 120048/120048 [00:04<00:00, 26234.93it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 49442/49442 [00:02<00:00, 18733.86it/s]\n"
     ]
    }
   ],
   "source": [
    "granularity = '_per_user'\n",
    "for dataset in datasets:\n",
    "    data_path = os.path.join(base_dir,'data','01_raw_data',dataset, dataset+granularity+'.pk')\n",
    "    with open(data_path, 'rb') as rf:\n",
    "        data = pk.load(rf)\n",
    "        url_ideology = data['urls'].progress_apply(lambda l: np.nanmean([get_url_ideology(e) for e in l])).apply(handle_labels)\n",
    "    Path( os.path.join(base_dir,'data','03_processed',dataset,'ground_truth') ).mkdir( parents=True, exist_ok=True )\n",
    "    with open(os.path.join(base_dir,'data','03_processed',dataset,'ground_truth', dataset+'_URLb_FR_'+granularity+'.pk'), 'wb') as wf:\n",
    "        pk.dump(url_ideology, wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0208a627",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Prep FR Seed User Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b43aa5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "far_right_df = pd.read_csv(os.path.join(base_dir,'data','02_ground_truth_data','far-right-users','far_right_coded_users.csv'), dtype=str)\n",
    "recent_far_right_df = pd.read_csv(os.path.join(base_dir,'data','02_ground_truth_data','far-right-users','auspol-2022-accounts_to_monitor.csv'), dtype=str)\n",
    "far_right_set = set(far_right_df['user_id']).union(recent_far_right_df['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a99d8f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['qanda', 'ausvotes', 'riot', 'parler', 'socialsense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a382e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "granularity = '_per_user'\n",
    "for dataset in datasets:\n",
    "    data_path = os.path.join(base_dir,'data','01_raw_data',dataset, dataset+granularity+'.pk')\n",
    "    with open(data_path, 'rb') as rf:\n",
    "        data = pk.load(rf).reset_index(drop=False)\n",
    "        fr_seed_gt =  data['uid'].isin(far_right_set)\n",
    "    Path( os.path.join(base_dir,'data','03_processed',dataset,'ground_truth') ).mkdir( parents=True, exist_ok=True )\n",
    "    with open(os.path.join(base_dir,'data','03_processed',dataset,'ground_truth', dataset+'_USER_FR_'+granularity+'.pk'), 'wb') as wf:\n",
    "        pk.dump(fr_seed_gt, wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32744d5",
   "metadata": {},
   "source": [
    "### Prep TPD Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5e7ee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpd_data = pd.read_csv(os.path.join(base_dir,'data','02_ground_truth_data','full_member_info.csv'),encoding = 'utf16', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8189e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpd_data = tpd_data[tpd_data['country'] == 'Australia']\n",
    "tpd_data = tpd_data[~tpd_data['uid'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "88e0d199",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpd_data = tpd_data[['name', 'party_id', 'party', 'uid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0c0116a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ideology(pi):\n",
    "    if pi == '464':\n",
    "        return 2\n",
    "    if pi == '465':\n",
    "        return 1\n",
    "    if pi == '467':\n",
    "        return 2\n",
    "    if pi == '468':\n",
    "        return 0\n",
    "    if pi == '469':\n",
    "        return 1\n",
    "    if pi == '471':\n",
    "        return 0\n",
    "    if pi == '475':\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f52c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpd_data['stance'] = tpd_data['party_id'].apply(get_ideology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b35889c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpd_data = tpd_data.set_index('uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ef3ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['qanda', 'ausvotes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66a611e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_politician_ideology(uid):\n",
    "    try:\n",
    "        return tpd_data.loc[uid].stance\n",
    "    except Exception as e:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0e80bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "granularity = '_per_user'\n",
    "for dataset in datasets:\n",
    "    data_path = os.path.join(base_dir,'data','01_raw_data',dataset, dataset+granularity+'.pk')\n",
    "    with open(data_path, 'rb') as rf:\n",
    "        data = pk.load(rf).reset_index(drop=False)\n",
    "        tpd_gt =  data['uid'].apply(get_politician_ideology)\n",
    "    Path( os.path.join(base_dir,'data','03_processed',dataset,'ground_truth') ).mkdir( parents=True, exist_ok=True )\n",
    "    with open(os.path.join(base_dir,'data','03_processed',dataset,'ground_truth', dataset+'_POLITICIAN_LR_'+granularity+'.pk'), 'wb') as wf:\n",
    "        pk.dump(tpd_gt, wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "544c3581-b3d9-4cb3-a806-19cc3bd90bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "granularity = '_per_user'\n",
    "for dataset in datasets:\n",
    "    data_path_per_user = os.path.join(base_dir,'data','01_raw_data',dataset, dataset+'_per_user'+'.pk')\n",
    "    data_path_per_post = os.path.join(base_dir,'data','01_raw_data',dataset, dataset+'_per_post'+'.pk')\n",
    "    with open(data_path_per_user, 'rb') as rf:\n",
    "        data_per_user = pk.load(rf).reset_index(drop=False)\n",
    "        tpd_gt =  data_per_user['uid'].apply(get_politician_ideology)\n",
    "    with open(data_path_per_post, 'rb') as rf:\n",
    "        data_per_post = pk.load(rf).reset_index(drop=False)\n",
    "        data_per_post['stance'] = data_per_post['uid'].apply(get_politician_ideology)\n",
    "\n",
    "        def most_common(lst):\n",
    "            data = Counter(lst)\n",
    "            return max(lst, key=data.get)\n",
    "\n",
    "        rid_stance_index = data_per_post[~data_per_post['stance'].isna()].groupby('rid').apply(lambda d: most_common(d['stance']))\n",
    "        def get_retweet_ideology(rid):\n",
    "            try:\n",
    "                return rid_stance_index.loc[rid]\n",
    "            except Exception as e:\n",
    "                return pd.NA\n",
    "        data_per_post['stance'] = data_per_post['rid'].apply(get_retweet_ideology)\n",
    "\n",
    "        uid_stance_index = data_per_post.groupby('uid').apply(lambda d: most_common(d['stance']))\n",
    "        uid_stance_index = uid_stance_index[~uid_stance_index.isna()]\n",
    "        def get_politician_1h_ideology(uid):\n",
    "            try:\n",
    "                return uid_stance_index.loc[uid]\n",
    "            except Exception as e:\n",
    "                return -1\n",
    "        tpd_1h_gt =  data_per_user['uid'].apply(get_politician_1h_ideology)\n",
    "        Path( os.path.join(base_dir,'data','03_processed',dataset,'ground_truth') ).mkdir( parents=True, exist_ok=True )\n",
    "        with open(os.path.join(base_dir,'data','03_processed',dataset,'ground_truth', dataset+'_POLITICIAN_1H_LR_'+'_per_user'+'.pk'), 'wb') as wf:\n",
    "            pk.dump(tpd_1h_gt, wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8956df11-3611-4555-8a0f-fdd7bde2a08f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prep Party Followers Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6573b09-c01a-4572-a5b9-fc1b51460d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "party_followers = pd.read_csv(os.path.join(base_dir, 'data','02_ground_truth_data','party_followers','data.csv'), names=['party','follower'], dtype='str')\n",
    "# .set_index('follower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f041de9e-660b-458c-a2d3-8a86401a0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiparty_followers = party_followers.groupby('follower')['party'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ef57f12-1890-4352-bba7-5b869ab724a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_party_followers = multiparty_followers[multiparty_followers ==1].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98b17aa7-d4ec-461e-88a4-887309de3745",
   "metadata": {},
   "outputs": [],
   "source": [
    "party_followers = party_followers[party_followers.follower.isin(single_party_followers)].set_index('follower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18658e45-0331-493e-9943-9a2dd7a58ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ideology(party):\n",
    "    if party == 'Climate200':\n",
    "        return 1\n",
    "    if party == 'Greens':\n",
    "        return 1\n",
    "    if party == 'AustralianLabor':\n",
    "        return 1\n",
    "    if party == 'centre_alliance':\n",
    "        return 0\n",
    "    if party == 'LambieNetwork':\n",
    "        return 0\n",
    "    if party == 'LiberalAus':\n",
    "        return 2\n",
    "    if party == 'The_Nationals':\n",
    "        return 2\n",
    "    if party == 'UnitedAusParty':\n",
    "        return 2\n",
    "    if party == 'KAPteam':\n",
    "        return 2\n",
    "    if party == 'OneNationAus':\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1af660f9-7d5e-4da7-903d-3d6abfa759d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "party_followers['stance'] = party_followers.party.apply(get_ideology)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97653c6b-871e-4758-9dd7-bf6af52d4165",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['qanda', 'ausvotes', 'riot', 'parler', 'socialsense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca1ad4bf-a35b-4fa0-a7f3-8003271a4225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_party_follower_ideology(uid):\n",
    "    try:\n",
    "        return party_followers.loc[uid].stance\n",
    "    except Exception as e:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38d72968-fcd6-4d96-8060-3db947c35166",
   "metadata": {},
   "outputs": [],
   "source": [
    "granularity = '_per_user'\n",
    "for dataset in datasets:\n",
    "    data_path = os.path.join(base_dir,'data','01_raw_data',dataset, dataset+granularity+'.pk')\n",
    "    with open(data_path, 'rb') as rf:\n",
    "        data = pk.load(rf).reset_index(drop=False)\n",
    "        merged_df = pd.merge(data, party_followers[['stance']],right_index=True,how='left', left_on='uid')\n",
    "        # merged_df = merged_df[~merged_df.index.duplicated()]\n",
    "        party_follower_gt = merged_df[~merged_df.index.duplicated()]['stance'].fillna(-1)\n",
    "        # party_follower_gt =  data['uid'].progress_apply(get_party_follower_ideology)\n",
    "        # party_follower_gt = np.array(Parallel(n_jobs=40, verbose=1)(delayed(get_party_follower_ideology)(uid) for uid in data['uid'].to_list()))\n",
    "    Path( os.path.join(base_dir,'data','03_processed',dataset,'ground_truth') ).mkdir( parents=True, exist_ok=True )\n",
    "    with open(os.path.join(base_dir,'data','03_processed',dataset,'ground_truth', dataset+'_PARTY_FOLLOWER_LR_'+granularity+'.pk'), 'wb') as wf:\n",
    "        pk.dump(party_follower_gt, wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1cb612-6121-473e-b196-17c8166c3ee2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Prep Validation Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0c79268-e5f4-4374-839f-0496c09ececd",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_validation = pd.read_csv(os.path.join(base_dir,'data','02_ground_truth_data','manual_validation','qanda_validated_2.csv'), dtype=str)\n",
    "manual_validation['stance'] = manual_validation.label.astype(int)\n",
    "manual_validation['uid'] = manual_validation.UID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a376aa5-9229-4a45-a56a-7a7e1ec20099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual_validation = pd.read_csv(os.path.join(base_dir,'data','02_ground_truth_data','qanda_manual_validation.csv'), dtype=str)\n",
    "# manual_validation['stance'] = manual_validation.stance.astype(int)\n",
    "# # manual_validation.loc[manual_validation['stance'] == -1,'stance'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c3a9caf-22a2-4851-84ee-92f8ff16b79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_validation = manual_validation[manual_validation['stance'] > -1][['uid','stance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0aff7411-0285-48ee-8db3-74d43d382359",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['qanda']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87acb317-25a7-4422-93fb-29653ae2ca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset in datasets:\n",
    "dataset='qanda'\n",
    "with open(os.path.join(base_dir,'data','01_raw_data',dataset, dataset+'_per_user'+'.pk'), 'rb') as rf:\n",
    "    data = pk.load(rf)\n",
    "    manual_val = pd.merge(data,manual_validation, on='uid', how='left').stance.fillna(-1)\n",
    "    Path( os.path.join(base_dir,'data','03_processed',dataset,'ground_truth') ).mkdir( parents=True, exist_ok=True )\n",
    "    with open(os.path.join(base_dir,'data','03_processed',dataset,'ground_truth', dataset+'_MANUAL_VALIDATION_LR_'+'_per_user'+'.pk'), 'wb') as wf:\n",
    "        pk.dump(manual_val, wf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8681d55-5ece-4064-884e-64be07e9f3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rr",
   "language": "python",
   "name": "rr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
