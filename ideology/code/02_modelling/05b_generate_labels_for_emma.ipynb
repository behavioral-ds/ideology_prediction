{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f53f7f8-85f1-4c3c-a1b1-b3cd742133d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "load_dotenv()\n",
    "base_dir = os.getenv('BASEDIR')\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "# from lightgbm import LGBMClassifier\n",
    "from flaml.default import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e1914e3-0e81-4a16-b2e7-968ed5a76a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49dad94a-6a5a-4fcb-bd81-cc074a61f295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0cd55a3-4dbc-4563-8242-b6971613b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = ['qanda', 'ausvotes','socialsense','riot', 'parler']\n",
    "# datasets = ['qanda']\n",
    "dataset='qanda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a711731a-a4e7-4989-8948-d4bd5cbe8981",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_twitter = {'qanda', 'ausvotes', 'riot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "157a0f18-c872-468a-9533-1bdd90bd65d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_fr_name = 'URLb_FR'\n",
    "features_lr=['use']\n",
    "features_fr=['use']\n",
    "\n",
    "granularity='_per_user'\n",
    "gt='URL_LR'\n",
    "data_path = os.path.join(base_dir,'data','01_raw_data',dataset, dataset+granularity+'.pk')\n",
    "with open(data_path, 'rb') as rf:\n",
    "    data = pk.load(rf).reset_index(drop=False)\n",
    "\n",
    "def load_vector(fp):\n",
    "    with open(fp, 'rb') as rf:\n",
    "        vec = pk.load(rf)\n",
    "    return vec\n",
    "\n",
    "feature_paths_lr = [os.path.join(base_dir,'data','03_processed',dataset,'features', dataset+'_'+feature+'_'+granularity+'.pk') for feature in features_lr]\n",
    "features_lr = np.asarray(np.hstack([load_vector(fp) for fp in feature_paths_lr]))\n",
    "\n",
    "feature_paths_fr = [os.path.join(base_dir,'data','03_processed',dataset,'features', dataset+'_'+feature+'_'+granularity+'.pk') for feature in features_fr]\n",
    "features_fr = np.asarray(np.hstack([load_vector(fp) for fp in feature_paths_fr]))\n",
    "\n",
    "gt_stance = load_vector(os.path.join(base_dir,'data','03_processed',dataset,'ground_truth', dataset+'_URL_LR_'+granularity+'.pk'))\n",
    "gt_fr = load_vector(os.path.join(base_dir,'data','03_processed',dataset,'ground_truth', dataset+'_'+gt_fr_name+'_'+granularity+'.pk'))    \n",
    "\n",
    "# Left-Right\n",
    "# et = LGBMClassifier(n_estimators=100, min_data_in_leaf=500,colsample_bytree=0.8, class_weight='balanced', n_jobs=-1)\n",
    "et_lr = LGBMClassifier(is_unbalance=True,n_estimators=200, n_jobs=-1, verbose=-1, seed=123)\n",
    "mask_stance = gt_stance >=0\n",
    "y_stance = gt_stance[mask_stance]\n",
    "X_stance = features_lr[mask_stance]\n",
    "et_lr.fit(X_stance,y_stance)\n",
    "predicted_stance = et_lr.predict(features_lr)\n",
    "\n",
    "# Far-Right\n",
    "# et = LGBMClassifier(n_estimators=100, min_data_in_leaf=500,colsample_bytree=0.8, class_weight='balanced', n_jobs=-1)\n",
    "et_fr = LGBMClassifier(is_unbalance=True, n_jobs=-1, verbose=-1, seed=123)\n",
    "# et = LGBMClassifier(n_estimators=200, n_jobs=-1, verbose=-1, seed=123)\n",
    "mask_fr = gt_fr >=0\n",
    "y_fr = gt_fr[mask_fr]\n",
    "X_fr = features_fr[mask_fr]\n",
    "et_fr.fit(X_fr,y_fr)\n",
    "predicted_fr = et_fr.predict(features_fr)\n",
    "\n",
    "pred_stance = pd.Series([['N', 'L', 'R'][i] for i in predicted_stance]).values\n",
    "\n",
    "label = pred_stance\n",
    "label[predicted_fr] = 'FR'\n",
    "data['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9abb7b1c-29fc-4f6e-8302-38725ca765d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(base_dir,'data','01_raw_data',dataset,dataset+'_per_post.pk'), 'rb') as rf:\n",
    "    data_per_post = pk.load(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76e649ff-4a46-4402-bd7b-bac968e93276",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_labels = data[['uid', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29b34c9d-dc42-4ef0-b998-c37810c03f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_per_post['user_propagated_label'] = pd.merge(data_per_post[['uid']], user_labels, how='left', on='uid')['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f13851-17be-414b-86f4-95b637085160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78e7fe90-cfa3-4eac-babc-66705de0d3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 12:30:08.868203: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-28 12:30:09.009675: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-28 12:30:09.016642: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roram/anaconda3/lib:\n",
      "2023-04-28 12:30:09.016656: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-04-28 12:30:09.042678: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-04-28 12:30:37.516464: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roram/anaconda3/lib:\n",
      "2023-04-28 12:30:37.518531: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roram/anaconda3/lib:\n",
      "2023-04-28 12:30:37.518538: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b89bf13-54c3-4fa7-9f33-a11b6ef13cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 12:32:25.597534: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roram/anaconda3/lib:\n",
      "2023-04-28 12:32:25.599880: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roram/anaconda3/lib:\n",
      "2023-04-28 12:32:25.601996: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roram/anaconda3/lib:\n",
      "2023-04-28 12:32:25.604096: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roram/anaconda3/lib:\n",
      "2023-04-28 12:32:25.606101: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roram/anaconda3/lib:\n",
      "2023-04-28 12:32:25.608172: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roram/anaconda3/lib:\n",
      "2023-04-28 12:32:25.610180: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roram/anaconda3/lib:\n",
      "2023-04-28 12:32:25.612252: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/roram/anaconda3/lib:\n",
      "2023-04-28 12:32:25.612261: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-04-28 12:32:25.671026: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    }
   ],
   "source": [
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "def embed(input):\n",
    "    return model(input)\n",
    "\n",
    "def batched_embed(l_text):\n",
    "    all_embeddings = []\n",
    "    chunk_size = 10\n",
    "    for i in tqdm(range(0, len(l_text), chunk_size)):\n",
    "        chunk = l_text[i: min(i+chunk_size, len(l_text))]\n",
    "        emb = embed(chunk)\n",
    "        all_embeddings.append(emb.numpy())\n",
    "    return np.vstack(all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33599fd9-991a-4cb2-933d-4a36f8f0a90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 125213/125213 [03:33<00:00, 586.12it/s]\n"
     ]
    }
   ],
   "source": [
    "use_embeddings = batched_embed(list(data_per_post['text']))\n",
    "features_lr = use_embeddings\n",
    "features_fr = use_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e54fc69b-4305-4195-8dcb-0a42288b7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stance = et_lr.predict(features_lr)\n",
    "predicted_fr = et_fr.predict(features_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dc120ab-1eed-4abd-af6f-0ed28396c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_stance = pd.Series([['N', 'L', 'R'][i] for i in predicted_stance]).values\n",
    "\n",
    "label = pred_stance\n",
    "label[predicted_fr] = 'FR'\n",
    "data_per_post['user_based_label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef699d25-430b-4ed0-819c-917bf4978caa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "879e5854-1786-4468-bb19-593df7bb4b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_lr = pd.read_csv(os.path.join(base_dir,'data','02_ground_truth_data','url_data','domain_allsides_reuters_lr.csv')).set_index('domain')\n",
    "\n",
    "import tldextract\n",
    "def extract_domain(url):\n",
    "    ext = tldextract.extract(url)\n",
    "    return('.'.join([ext.domain, ext.suffix]))\n",
    "\n",
    "def handle_labels(s):\n",
    "    if np.isnan(s):\n",
    "        return -1\n",
    "    elif s > 0:\n",
    "        return 2\n",
    "    elif s == 0:\n",
    "        return 0\n",
    "    elif s < -1*0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def get_url_ideology(full_url):\n",
    "    domain = extract_domain(full_url)\n",
    "    try:\n",
    "        return(domain_lr.loc[domain].stance)\n",
    "    except Exception as e:\n",
    "        return(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f70fe53-c0b2-478d-90ae-6f6b27794b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                              | 0/1252122 [00:00<?, ?it/s]/tmp/ipykernel_221119/854998142.py:1: RuntimeWarning: Mean of empty slice\n",
      "  gt_stance = data_per_post['urls'].progress_apply(lambda l: np.nanmean([get_url_ideology(e) for e in l])).apply(handle_labels)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1252122/1252122 [01:03<00:00, 19672.86it/s]\n"
     ]
    }
   ],
   "source": [
    "gt_stance = data_per_post['urls'].progress_apply(lambda l: np.nanmean([get_url_ideology(e) for e in l])).apply(handle_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7da6f394-3511-4f44-ae08-b126ce041ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbfc = pd.read_csv(os.path.join(base_dir,'data','02_ground_truth_data','url_data','mbfc','mbfc_poltical.tsv'), delimiter='\\t')\n",
    "mbfc = pd.read_csv(os.path.join(base_dir,'data','02_ground_truth_data','url_data','mbfc','mbfc_poltical.tsv'), delimiter='\\t')\n",
    "mbfc = mbfc[mbfc['bias'] == 'right']\n",
    "mbfc['domain'] = mbfc['source_url_normalized']\n",
    "mbfc['stance'] = 1.0\n",
    "mbfc = mbfc.set_index('domain')\n",
    "import tldextract\n",
    "def extract_domain(url):\n",
    "    ext = tldextract.extract(url)\n",
    "    return('.'.join([ext.domain, ext.suffix]))\n",
    "\n",
    "def handle_labels(s):\n",
    "    return s > 0.5\n",
    "    \n",
    "def get_url_ideology(full_url):\n",
    "    domain = extract_domain(full_url)\n",
    "    try:\n",
    "        return(mbfc.loc[domain].stance)\n",
    "    except Exception as e:\n",
    "        return(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f49ad83-431a-4a75-9d7f-ea30632d5f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                              | 0/1252122 [00:00<?, ?it/s]/tmp/ipykernel_221119/1023213283.py:1: RuntimeWarning: Mean of empty slice\n",
      "  gt_fr = data_per_post['urls'].progress_apply(lambda l: np.nanmean([get_url_ideology(e) for e in l])).apply(handle_labels)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1252122/1252122 [01:01<00:00, 20242.94it/s]\n"
     ]
    }
   ],
   "source": [
    "gt_fr = data_per_post['urls'].progress_apply(lambda l: np.nanmean([get_url_ideology(e) for e in l])).apply(handle_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c9e984-5358-43ce-9a5e-ef8fec9791c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "110b952f-66eb-403e-b4a4-8f8ae079358b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:flaml.default.suggest:metafeature distance: 0.7131673427388265\n",
      "INFO:flaml.default.suggest:metafeature distance: 18.63728940022159\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Left-Right\n",
    "# et = LGBMClassifier(n_estimators=100, min_data_in_leaf=500,colsample_bytree=0.8, class_weight='balanced', n_jobs=-1)\n",
    "et_lr = LGBMClassifier(is_unbalance=True,n_estimators=200, n_jobs=-1, verbose=-1, seed=123)\n",
    "mask_stance = gt_stance >=0\n",
    "y_stance = gt_stance[mask_stance]\n",
    "X_stance = features_lr[mask_stance]\n",
    "et_lr.fit(X_stance,y_stance)\n",
    "predicted_stance = et_lr.predict(features_lr)\n",
    "\n",
    "# Far-Right\n",
    "# et = LGBMClassifier(n_estimators=100, min_data_in_leaf=500,colsample_bytree=0.8, class_weight='balanced', n_jobs=-1)\n",
    "et_fr = LGBMClassifier(is_unbalance=True, n_jobs=-1, verbose=-1, seed=123)\n",
    "# et = LGBMClassifier(n_estimators=200, n_jobs=-1, verbose=-1, seed=123)\n",
    "mask_fr = gt_fr >=0\n",
    "y_fr = gt_fr[mask_fr]\n",
    "X_fr = features_fr[mask_fr]\n",
    "et_fr.fit(X_fr,y_fr)\n",
    "predicted_fr = et_fr.predict(features_fr)\n",
    "\n",
    "pred_stance = pd.Series([['N', 'L', 'R'][i] for i in predicted_stance]).values\n",
    "\n",
    "label = pred_stance\n",
    "label[predicted_fr] = 'FR'\n",
    "data_per_post['tweet_based_label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b78f8f8-56df-4563-a4fc-92ec8f25a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(os.path.join(base_dir,'data','04_results','labels_emma')).mkdir( parents=True, exist_ok=True )\n",
    "data_per_post[['tid','uid','user_propagated_label', 'user_based_label', 'tweet_based_label']].to_csv(os.path.join(base_dir,'data','04_results','labels_emma',dataset+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1aab3b0-fc9c-4f89-842d-1a6815c5fd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tid                      object\n",
       "uid                      object\n",
       "user_propagated_label    object\n",
       "user_based_label         object\n",
       "tweet_based_label        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_per_post[['tid','uid','user_propagated_label', 'user_based_label', 'tweet_based_label']].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e7ec8-08ca-4b08-91ed-67a8b6b3d9c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe62ee1-94bc-4529-98d6-35c1a57f6c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_fr_name = 'URLb_FR'\n",
    "features_lr=['use']\n",
    "features_fr=['use']\n",
    "\n",
    "granularity='_per_user'\n",
    "gt='URL_LR'\n",
    "data_path = os.path.join(base_dir,'data','01_raw_data',dataset, dataset+granularity+'.pk')\n",
    "with open(data_path, 'rb') as rf:\n",
    "    data = pk.load(rf).reset_index(drop=False)\n",
    "\n",
    "def load_vector(fp):\n",
    "    with open(fp, 'rb') as rf:\n",
    "        vec = pk.load(rf)\n",
    "    return vec\n",
    "\n",
    "feature_paths_lr = [os.path.join(base_dir,'data','03_processed',dataset,'features', dataset+'_'+feature+'_'+granularity+'.pk') for feature in features_lr]\n",
    "features_lr = np.asarray(np.hstack([load_vector(fp) for fp in feature_paths_lr]))\n",
    "\n",
    "feature_paths_fr = [os.path.join(base_dir,'data','03_processed',dataset,'features', dataset+'_'+feature+'_'+granularity+'.pk') for feature in features_fr]\n",
    "features_fr = np.asarray(np.hstack([load_vector(fp) for fp in feature_paths_fr]))\n",
    "\n",
    "gt_stance = load_vector(os.path.join(base_dir,'data','03_processed',dataset,'ground_truth', dataset+'_URL_LR_'+granularity+'.pk'))\n",
    "gt_fr = load_vector(os.path.join(base_dir,'data','03_processed',dataset,'ground_truth', dataset+'_'+gt_fr_name+'_'+granularity+'.pk'))    \n",
    "\n",
    "# Left-Right\n",
    "# et = LGBMClassifier(n_estimators=100, min_data_in_leaf=500,colsample_bytree=0.8, class_weight='balanced', n_jobs=-1)\n",
    "et_lr = LGBMClassifier(is_unbalance=True,n_estimators=200, n_jobs=-1, verbose=-1, seed=123)\n",
    "mask_stance = gt_stance >=0\n",
    "y_stance = gt_stance[mask_stance]\n",
    "X_stance = features_lr[mask_stance]\n",
    "et_lr.fit(X_stance,y_stance)\n",
    "predicted_stance = et_lr.predict(features_lr)\n",
    "\n",
    "# Far-Right\n",
    "# et = LGBMClassifier(n_estimators=100, min_data_in_leaf=500,colsample_bytree=0.8, class_weight='balanced', n_jobs=-1)\n",
    "et_fr = LGBMClassifier(is_unbalance=True, n_jobs=-1, verbose=-1, seed=123)\n",
    "# et = LGBMClassifier(n_estimators=200, n_jobs=-1, verbose=-1, seed=123)\n",
    "mask_fr = gt_fr >=0\n",
    "y_fr = gt_fr[mask_fr]\n",
    "X_fr = features_fr[mask_fr]\n",
    "et_fr.fit(X_fr,y_fr)\n",
    "predicted_fr = et_fr.predict(features_fr)\n",
    "\n",
    "pred_stance = pd.Series([['N', 'L', 'R'][i] for i in predicted_stance]).values\n",
    "\n",
    "label = pred_stance\n",
    "label[predicted_fr] = 'FR'\n",
    "data['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a736eb2c-b52e-4061-a517-9f0a9da83981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b821c72-cebe-4927-9e29-ef43fb83a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(os.path.join(base_dir,'data','04_results','labels_emma')).mkdir( parents=True, exist_ok=True )\n",
    "data[['uid','label']].to_csv(os.path.join(base_dir,'data','04_results','labels_emma',dataset+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdae7cb5-56b3-4bf5-bbed-83c13acc341d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13dbca52-2253-404c-996b-706f4d2e5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "load_dotenv()\n",
    "base_dir = os.getenv('BASEDIR')\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "# from lightgbm import LGBMClassifier\n",
    "from flaml.default import LGBMClassifier\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "907fcfdb-e009-4483-a510-590c84bb42a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['qanda', 'ausvotes','socialsense','riot', 'parler']\n",
    "# datasets = ['riot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd690375-a1e2-45c0-9018-cddfb1258273",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_twitter = {'qanda', 'ausvotes', 'riot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48e7da0b-874f-4f87-b909-51b3c19a4ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: lr\n",
      "Trained: lr\n",
      "Training: fr\n",
      "Trained: fr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                  | 0/5 [1:09:41<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Wrong number of items passed 3, placement implies 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/data/roram/anaconda3/envs/rr/lib/python3.10/site-packages/pandas/core/indexes/base.py:3361\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/data/roram/anaconda3/envs/rr/lib/python3.10/site-packages/pandas/_libs/index.pyx:76\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/data/roram/anaconda3/envs/rr/lib/python3.10/site-packages/pandas/_libs/index.pyx:108\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lr_prob'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/data/roram/anaconda3/envs/rr/lib/python3.10/site-packages/pandas/core/frame.py:3751\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3750\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3751\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3752\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   3753\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n",
      "File \u001b[0;32m/data/roram/anaconda3/envs/rr/lib/python3.10/site-packages/pandas/core/indexes/base.py:3363\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3362\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3363\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3365\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_scalar(key) \u001b[38;5;129;01mand\u001b[39;00m isna(key) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhasnans:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'lr_prob'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m label[predicted_fr] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFR\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     57\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m label\n\u001b[0;32m---> 59\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_prob\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m predicted_stance_proba\n\u001b[1;32m     60\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr_label\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m predicted_stance\n\u001b[1;32m     62\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfr_prob\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m predicted_fr_proba\n",
      "File \u001b[0;32m/data/roram/anaconda3/envs/rr/lib/python3.10/site-packages/pandas/core/frame.py:3612\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3609\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3610\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3611\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3612\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/roram/anaconda3/envs/rr/lib/python3.10/site-packages/pandas/core/frame.py:3797\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(existing_piece, DataFrame):\n\u001b[1;32m   3795\u001b[0m             value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(value, (\u001b[38;5;28mlen\u001b[39m(existing_piece\u001b[38;5;241m.\u001b[39mcolumns), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m-> 3797\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/roram/anaconda3/envs/rr/lib/python3.10/site-packages/pandas/core/frame.py:3754\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3751\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3752\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m   3753\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n\u001b[0;32m-> 3754\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_info_axis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3755\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3756\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iset_item_mgr(loc, value)\n",
      "File \u001b[0;32m/data/roram/anaconda3/envs/rr/lib/python3.10/site-packages/pandas/core/internals/managers.py:1162\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[0;34m(self, loc, item, value)\u001b[0m\n\u001b[1;32m   1159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1160\u001b[0m     value \u001b[38;5;241m=\u001b[39m ensure_block_shape(value, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m-> 1162\u001b[0m block \u001b[38;5;241m=\u001b[39m \u001b[43mnew_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blkno, count \u001b[38;5;129;01min\u001b[39;00m _fast_count_smallints(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblknos[loc:]):\n\u001b[1;32m   1165\u001b[0m     blk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks[blkno]\n",
      "File \u001b[0;32m/data/roram/anaconda3/envs/rr/lib/python3.10/site-packages/pandas/core/internals/blocks.py:1937\u001b[0m, in \u001b[0;36mnew_block\u001b[0;34m(values, placement, ndim, klass)\u001b[0m\n\u001b[1;32m   1934\u001b[0m     placement \u001b[38;5;241m=\u001b[39m BlockPlacement(placement)\n\u001b[1;32m   1936\u001b[0m values, _ \u001b[38;5;241m=\u001b[39m extract_pandas_array(values, \u001b[38;5;28;01mNone\u001b[39;00m, ndim)\n\u001b[0;32m-> 1937\u001b[0m \u001b[43mcheck_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m klass \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1940\u001b[0m     klass \u001b[38;5;241m=\u001b[39m get_block_type(values, values\u001b[38;5;241m.\u001b[39mdtype)\n",
      "File \u001b[0;32m/data/roram/anaconda3/envs/rr/lib/python3.10/site-packages/pandas/core/internals/blocks.py:1979\u001b[0m, in \u001b[0;36mcheck_ndim\u001b[0;34m(values, placement, ndim)\u001b[0m\n\u001b[1;32m   1974\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1975\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong number of dimensions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1976\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues.ndim != ndim [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalues\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1977\u001b[0m         )\n\u001b[1;32m   1978\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(placement) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(values):\n\u001b[0;32m-> 1979\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1980\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong number of items passed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(values)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1981\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplacement implies \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(placement)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1982\u001b[0m         )\n\u001b[1;32m   1983\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(placement) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1984\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special case unnecessary with 2D EAs\u001b[39;00m\n\u001b[1;32m   1985\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneed to split\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 3, placement implies 1"
     ]
    }
   ],
   "source": [
    "gt_fr_name = 'URLb_FR'\n",
    "for dataset in tqdm(datasets):\n",
    "    if dataset in datasets_twitter:\n",
    "        features_lr=['use', 'rt']\n",
    "        features_fr=['use', 'ht']\n",
    "        # features_fr= ['use']\n",
    "    else:\n",
    "        features_lr= ['use']\n",
    "        features_fr= ['use']\n",
    "    \n",
    "    granularity='_per_user'\n",
    "    gt='URL_LR'\n",
    "    data_path = os.path.join(base_dir,'data','01_raw_data',dataset, dataset+granularity+'.pk')\n",
    "    with open(data_path, 'rb') as rf:\n",
    "        data = pk.load(rf).reset_index(drop=False)\n",
    "        \n",
    "    def load_vector(fp):\n",
    "        with open(fp, 'rb') as rf:\n",
    "            vec = pk.load(rf)\n",
    "        return vec\n",
    "    \n",
    "    feature_paths_lr = [os.path.join(base_dir,'data','03_processed',dataset,'features', dataset+'_'+feature+'_'+granularity+'.pk') for feature in features_lr]\n",
    "    features_lr = np.asarray(np.hstack([load_vector(fp) for fp in feature_paths_lr]))\n",
    "    \n",
    "    feature_paths_fr = [os.path.join(base_dir,'data','03_processed',dataset,'features', dataset+'_'+feature+'_'+granularity+'.pk') for feature in features_fr]\n",
    "    features_fr = np.asarray(np.hstack([load_vector(fp) for fp in feature_paths_fr]))\n",
    "    \n",
    "    gt_stance = load_vector(os.path.join(base_dir,'data','03_processed',dataset,'ground_truth', dataset+'_URL_LR_'+granularity+'.pk'))\n",
    "    gt_fr = load_vector(os.path.join(base_dir,'data','03_processed',dataset,'ground_truth', dataset+'_'+gt_fr_name+'_'+granularity+'.pk'))    \n",
    "\n",
    "    # Left-Right\n",
    "    et = LGBMClassifier(is_unbalance=True,n_estimators=200, n_jobs=-1, verbose=-1, seed=41)\n",
    "    mask_stance = gt_stance >=0\n",
    "    y_stance = gt_stance[mask_stance]\n",
    "    X_stance = features_lr[mask_stance]\n",
    "    print('Training:', 'lr')\n",
    "    et.fit(X_stance,y_stance)\n",
    "    print('Trained:', 'lr')\n",
    "    predicted_stance = et.predict(features_lr)\n",
    "    predicted_stance_proba = et.predict_proba(features_lr)\n",
    "    \n",
    "    # Far-Right\n",
    "    et = LGBMClassifier(is_unbalance=True, n_jobs=-1, verbose=-1, seed=123)\n",
    "    mask_fr = gt_fr >=0\n",
    "    y_fr = gt_fr[mask_fr]\n",
    "    X_fr = features_fr[mask_fr]\n",
    "    print('Training:', 'fr')\n",
    "    et.fit(X_fr,y_fr)\n",
    "    print('Trained:', 'fr')\n",
    "    predicted_fr = et.predict(features_fr)\n",
    "    predicted_fr_proba = et.predict_proba(features_fr)\n",
    "                        \n",
    "    pred_stance = pd.Series([['N', 'L', 'R'][i] for i in predicted_stance]).values\n",
    "    \n",
    "    label = pred_stance\n",
    "    label[predicted_fr] = 'FR'\n",
    "    data['label'] = label\n",
    "    data['lr_prob_left'] = predicted_stance_proba[:,1]\n",
    "\n",
    "    data['lr_prob_right'] = predicted_stance_proba[:,2]\n",
    "\n",
    "    data['lr_label'] = pd.Series([['N', 'L', 'R'][i] for i in predicted_stance]).values\n",
    "\n",
    "    data['fr_prob'] = predicted_fr_proba[:,1]\n",
    "\n",
    "    data['fr_label'] = predicted_fr\n",
    "\n",
    "    Path(os.path.join(base_dir,'data','04_results','labels')).mkdir( parents=True, exist_ok=True )\n",
    "    data[['uid','label','lr_prob_left','lr_prob_right', 'lr_label', 'fr_prob', 'fr_label']].to_csv(os.path.join(base_dir,'data','04_results','labels',dataset+'_extended.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c0316c87-53c5-40f8-99d4-bce44ae006cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lr_prob_left'] = predicted_stance_proba[:,1]\n",
    "\n",
    "data['lr_prob_right'] = predicted_stance_proba[:,2]\n",
    "\n",
    "data['lr_label'] = pd.Series([['N', 'L', 'R'][i] for i in predicted_stance]).values\n",
    "\n",
    "data['fr_prob'] = predicted_fr_proba[:,1]\n",
    "\n",
    "data['fr_label'] = predicted_fr\n",
    "\n",
    "Path(os.path.join(base_dir,'data','04_results','labels')).mkdir( parents=True, exist_ok=True )\n",
    "data[['uid','label','lr_prob_left','lr_prob_right', 'lr_label', 'fr_prob', 'fr_label']].to_csv(os.path.join(base_dir,'data','04_results','labels',dataset+'_extended.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc0e0417-000e-4754-8fc2-0e86d39378af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d83644e7-feb1-445f-a78f-f03064c85599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.29330231, 0.99298013, 0.99981708, ..., 0.99591776, 0.9874386 ,\n",
       "       0.99372335])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_stance_proba[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "434338ad-e48c-43e0-88b2-ae60eefda1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lr_prob_left'] = predicted_stance_proba[:,1]\n",
    "\n",
    "data['lr_prob_right'] = predicted_stance_proba[:,2]\n",
    "\n",
    "data['lr_label'] = pred_stance\n",
    "\n",
    "data['fr_prob'] = predicted_fr_proba[:,1]\n",
    "\n",
    "data['fr_label'] = predicted_fr\n",
    "\n",
    "Path(os.path.join(base_dir,'data','04_results','labels')).mkdir( parents=True, exist_ok=True )\n",
    "data[['uid','label','lr_prob_left','lr_prob_right', 'lr_label', 'fr_prob', 'fr_label']].to_csv(os.path.join(base_dir,'data','04_results','labels',dataset+'_extended.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dcb2665e-e776-4263-82ba-49d1acdde06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>level_1</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>rid</th>\n",
       "      <th>urls</th>\n",
       "      <th>label</th>\n",
       "      <th>lr_prob_left</th>\n",
       "      <th>lr_prob_right</th>\n",
       "      <th>lr_label</th>\n",
       "      <th>fr_prob</th>\n",
       "      <th>fr_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001245946490880</td>\n",
       "      <td>0</td>\n",
       "      <td>here we come!!  is   with  1st March!  on  no...</td>\n",
       "      <td>[Wolverhampton, screening, QandA, Tickets, sal...</td>\n",
       "      <td>[1225781455386796033]</td>\n",
       "      <td>[http://light-house.co.uk/LightHouseMedi]</td>\n",
       "      <td>N</td>\n",
       "      <td>0.293302</td>\n",
       "      <td>0.003465</td>\n",
       "      <td>N</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000022700092411904</td>\n",
       "      <td>0</td>\n",
       "      <td>when will you invite  on   Australian childre...</td>\n",
       "      <td>[qanda, GretaThunberg]</td>\n",
       "      <td>[1236486564550565888]</td>\n",
       "      <td>[]</td>\n",
       "      <td>L</td>\n",
       "      <td>0.992980</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>L</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000111986917572608</td>\n",
       "      <td>0</td>\n",
       "      <td>My daughter was lucky to finish her diploma bu...</td>\n",
       "      <td>[QandA, qanda, universities, QandA, qanda, shu...</td>\n",
       "      <td>[1297865209139228672, 1300401525051645953, 122...</td>\n",
       "      <td>[]</td>\n",
       "      <td>L</td>\n",
       "      <td>0.999817</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>L</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000127207048728576</td>\n",
       "      <td>0</td>\n",
       "      <td>Will you be one of the 99.99% of Australians n...</td>\n",
       "      <td>[blacklivesmatteraustralia, auspol, qanda, 9to...</td>\n",
       "      <td>[1269083271930896384]</td>\n",
       "      <td>[]</td>\n",
       "      <td>L</td>\n",
       "      <td>0.793648</td>\n",
       "      <td>0.014002</td>\n",
       "      <td>L</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000175125608583168</td>\n",
       "      <td>0</td>\n",
       "      <td>wheeling out clickbait promos that feed a def...</td>\n",
       "      <td>[QandA, aussieED, qanda, aussieED, qanda, wome...</td>\n",
       "      <td>[1235133197601492994, 1235107041477156865, 123...</td>\n",
       "      <td>[https://www.abc.net.au/qanda/2020-27-04/12165...</td>\n",
       "      <td>L</td>\n",
       "      <td>0.999689</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>L</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103069</th>\n",
       "      <td>999931831364435968</td>\n",
       "      <td>0</td>\n",
       "      <td>RT  Meyne Wyatt closes  with a monologue from ...</td>\n",
       "      <td>[QandA]</td>\n",
       "      <td>[1269982640494411776]</td>\n",
       "      <td>[]</td>\n",
       "      <td>L</td>\n",
       "      <td>0.997396</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>L</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103070</th>\n",
       "      <td>999937171766235136</td>\n",
       "      <td>0</td>\n",
       "      <td>I said prior to this particular Q&amp;amp;A sh...</td>\n",
       "      <td>[DefundTheABC]</td>\n",
       "      <td>[1270989483844841473, 1270989483844841473, 130...</td>\n",
       "      <td>[]</td>\n",
       "      <td>L</td>\n",
       "      <td>0.974676</td>\n",
       "      <td>0.022946</td>\n",
       "      <td>L</td>\n",
       "      <td>0.040587</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103071</th>\n",
       "      <td>999954234119356416</td>\n",
       "      <td>0</td>\n",
       "      <td>I know some folks are miffed I didn't get more...</td>\n",
       "      <td>[QandA]</td>\n",
       "      <td>[1224309168909082625, 1269982640494411776]</td>\n",
       "      <td>[]</td>\n",
       "      <td>L</td>\n",
       "      <td>0.995918</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>L</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103072</th>\n",
       "      <td>999960633960316929</td>\n",
       "      <td>0</td>\n",
       "      <td>RT  Rio Tinto “oops we didnt know it was that ...</td>\n",
       "      <td>[qanda, QandA, auspol2020]</td>\n",
       "      <td>[1267430023620788227, 1320679824331993088]</td>\n",
       "      <td>[]</td>\n",
       "      <td>L</td>\n",
       "      <td>0.987439</td>\n",
       "      <td>0.001694</td>\n",
       "      <td>L</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103073</th>\n",
       "      <td>999968158231363585</td>\n",
       "      <td>0</td>\n",
       "      <td>The apprenticeship scheme sounds great, howev...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1313077187893841920]</td>\n",
       "      <td>[]</td>\n",
       "      <td>L</td>\n",
       "      <td>0.993723</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>L</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103074 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        uid  level_1  \\\n",
       "0       1000001245946490880        0   \n",
       "1       1000022700092411904        0   \n",
       "2       1000111986917572608        0   \n",
       "3       1000127207048728576        0   \n",
       "4       1000175125608583168        0   \n",
       "...                     ...      ...   \n",
       "103069   999931831364435968        0   \n",
       "103070   999937171766235136        0   \n",
       "103071   999954234119356416        0   \n",
       "103072   999960633960316929        0   \n",
       "103073   999968158231363585        0   \n",
       "\n",
       "                                                     text  \\\n",
       "0        here we come!!  is   with  1st March!  on  no...   \n",
       "1        when will you invite  on   Australian childre...   \n",
       "2       My daughter was lucky to finish her diploma bu...   \n",
       "3       Will you be one of the 99.99% of Australians n...   \n",
       "4        wheeling out clickbait promos that feed a def...   \n",
       "...                                                   ...   \n",
       "103069  RT  Meyne Wyatt closes  with a monologue from ...   \n",
       "103070      I said prior to this particular Q&amp;A sh...   \n",
       "103071  I know some folks are miffed I didn't get more...   \n",
       "103072  RT  Rio Tinto “oops we didnt know it was that ...   \n",
       "103073   The apprenticeship scheme sounds great, howev...   \n",
       "\n",
       "                                                 hashtags  \\\n",
       "0       [Wolverhampton, screening, QandA, Tickets, sal...   \n",
       "1                                  [qanda, GretaThunberg]   \n",
       "2       [QandA, qanda, universities, QandA, qanda, shu...   \n",
       "3       [blacklivesmatteraustralia, auspol, qanda, 9to...   \n",
       "4       [QandA, aussieED, qanda, aussieED, qanda, wome...   \n",
       "...                                                   ...   \n",
       "103069                                            [QandA]   \n",
       "103070                                     [DefundTheABC]   \n",
       "103071                                            [QandA]   \n",
       "103072                         [qanda, QandA, auspol2020]   \n",
       "103073                                                 []   \n",
       "\n",
       "                                                      rid  \\\n",
       "0                                   [1225781455386796033]   \n",
       "1                                   [1236486564550565888]   \n",
       "2       [1297865209139228672, 1300401525051645953, 122...   \n",
       "3                                   [1269083271930896384]   \n",
       "4       [1235133197601492994, 1235107041477156865, 123...   \n",
       "...                                                   ...   \n",
       "103069                              [1269982640494411776]   \n",
       "103070  [1270989483844841473, 1270989483844841473, 130...   \n",
       "103071         [1224309168909082625, 1269982640494411776]   \n",
       "103072         [1267430023620788227, 1320679824331993088]   \n",
       "103073                              [1313077187893841920]   \n",
       "\n",
       "                                                     urls label  lr_prob_left  \\\n",
       "0               [http://light-house.co.uk/LightHouseMedi]     N      0.293302   \n",
       "1                                                      []     L      0.992980   \n",
       "2                                                      []     L      0.999817   \n",
       "3                                                      []     L      0.793648   \n",
       "4       [https://www.abc.net.au/qanda/2020-27-04/12165...     L      0.999689   \n",
       "...                                                   ...   ...           ...   \n",
       "103069                                                 []     L      0.997396   \n",
       "103070                                                 []     L      0.974676   \n",
       "103071                                                 []     L      0.995918   \n",
       "103072                                                 []     L      0.987439   \n",
       "103073                                                 []     L      0.993723   \n",
       "\n",
       "        lr_prob_right lr_label   fr_prob  fr_label  \n",
       "0            0.003465        N  0.000076     False  \n",
       "1            0.000464        L  0.000237     False  \n",
       "2            0.000127        L  0.000214     False  \n",
       "3            0.014002        L  0.000277     False  \n",
       "4            0.000066        L  0.000810     False  \n",
       "...               ...      ...       ...       ...  \n",
       "103069       0.000515        L  0.000039     False  \n",
       "103070       0.022946        L  0.040587     False  \n",
       "103071       0.000132        L  0.000085     False  \n",
       "103072       0.001694        L  0.000108     False  \n",
       "103073       0.001650        L  0.000061     False  \n",
       "\n",
       "[103074 rows x 12 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eba69e-b46a-494e-82be-59bda4155161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rr",
   "language": "python",
   "name": "rr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
